import numpy as np
import torch
from torch.nn import functional as F
from scipy.ndimage import gaussian_filter


def weight_decision_mechanism(n, output_list, alpha, beta, out_size=256):
    """
    n: The number of test samples
    output_list: List of features generated by minimizing the outputs of different layers of models
    alpha and beta: Hyperparameters for controlling upper and lower limit

    return: anomaly score for anomaly detection, anomaly map for anomaly segmentation
    """
    total_weights_list = list()

    for i in range(n):
        low_sim_list = list()
        for j in range(len(output_list)):
            low_sim_list.append(torch.max(output_list[j][i]).cpu())
        probs = F.softmax(torch.tensor(low_sim_list), dim=0)
        weight_list = list()

        for idx, prob in enumerate(probs):
            if prob > torch.mean(probs):
                weight_list.append(low_sim_list[idx].numpy())
        weight = np.max([np.mean(weight_list) * alpha, beta])
        total_weights_list.append(weight)

    assert (
        len(total_weights_list) == n
    ), "the number of weights dose not match that of samples!"

    am_lists = [list() for _ in output_list]
    for l, output in enumerate(output_list):
        output = torch.cat(output, dim=0)
        a_map = torch.unsqueeze(output, dim=1)
